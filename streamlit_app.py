# Force Streamlit Cloud Redeploy
import streamlit as st
import openai
from openai import OpenAI
import os
import pdfplumber
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from pathlib import Path
from pptx import Presentation  # <-- NEW!

# Title
st.title("ðŸ“š PTA Tutor Chatbot with Quiz & Performance Tracker")

# --- Course Selection ---
course = st.selectbox("Select your course:", ["PTA_1010"])
course_folder = f"course_materials/{course}"

# --- Load PDF content ---
def load_pdf_text(folder):
    text = ""
    if os.path.exists(folder):
        for filename in os.listdir(folder):
            if filename.endswith(".pdf"):
                file_path = os.path.join(folder, filename)
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text
    return text

pdf_text = load_pdf_text(course_folder)[:3000]

# --- NEW: PowerPoint notes extraction ---
def extract_notes_from_uploaded_pptx(uploaded_file):
    prs = Presentation(uploaded_file)
    all_notes = []
    for i, slide in enumerate(prs.slides):
        slide_title = slide.shapes.title.text if slide.shapes.title else f"Slide {i+1}"
        notes_text = ""
        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:
            notes_text = slide.notes_slide.notes_text_frame.text.strip()
        all_notes.append(f"{slide_title}:\n{notes_text}\n")
    return "\n".join(all_notes)

# --- PPTX Upload UI ---
st.sidebar.header("Optional: Upload PowerPoint for Chatbot Content")
uploaded_pptx = st.sidebar.file_uploader("Upload a PowerPoint (.pptx)", type="pptx")
pptx_text = ""
if uploaded_pptx:
    pptx_text = extract_notes_from_uploaded_pptx(uploaded_pptx)
    st.sidebar.success("PowerPoint notes extracted. Chatbot will use these as course content.")

# --- OpenAI setup ---
openai_api_key = st.secrets["openai"]["api_key"]
openai.api_key = openai_api_key
client = OpenAI(api_key=openai_api_key)

# --- Grading log setup ---
log_path = Path("grading_log.csv")
if not log_path.exists():
    pd.DataFrame(columns=[
        "question_id", "question_text", "user_answer",
        "correct_answer", "correct", "timestamp"
    ]).to_csv(log_path, index=False)

# --- Chatbot Section ---
st.header("ðŸ’¬ Chat with the Tutor")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Display prior messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Handle input
if prompt := st.chat_input("Ask a question about your course..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # --- Use pptx_text if available, otherwise pdf_text ---
    course_content = pptx_text if pptx_text else pdf_text

    system_prompt = {
        "role": "system",
        "content": f"""You are a knowledgeable and focused PTA tutor.

Use ONLY this course content to answer questions:

{course_content}

If the question is unrelated to the material, respond: 'I'm sorry, I can only help with the course content provided.'"""
    }

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[system_prompt] + st.session_state.messages
        )
        reply = response.choices[0].message.content
        with st.chat_message("assistant"):
            st.markdown(reply)
        st.session_state.messages.append({"role": "assistant", "content": reply})
    except Exception as e:
        st.error(f"âŒ Error: {str(e)}")
        
# --- Quiz Generator ---
st.header("ðŸ“ Quiz Generator")

if st.button("Generate Quiz"):
    # Use pptx_text if available, otherwise pdf_text
    course_content = pptx_text if pptx_text else pdf_text

    quiz_prompt = (
        "You are a PTA tutor. Based on the following material, create 3 multiple-choice questions. "
        "Each should have 4 options (Aâ€“D) and include the correct answer after each question:\n\n"
        + course_content
    )
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": quiz_prompt}]
        )
        quiz_text = response.choices[0].message.content
        st.markdown("### âœï¸ Quiz Output")
        st.markdown(quiz_text)

        # Simulated grading
        sample_log = [
            {
                "question_id": "Q001",
                "question_text": "What is the primary muscle responsible for knee extension?",
                "user_answer": "A",
                "correct_answer": "A",
                "correct": 1,
                "timestamp": datetime.now().isoformat()
            },
            {
                "question_id": "Q002",
                "question_text": "Which is a contraindication to ultrasound?",
                "user_answer": "C",
                "correct_answer": "A",
                "correct": 0,
                "timestamp": datetime.now().isoformat()
            }
        ]

        df = pd.read_csv(log_path)
        df = pd.concat([df, pd.DataFrame(sample_log)], ignore_index=True)
        df.to_csv(log_path, index=False)

    except Exception as e:
        st.error(f"âŒ Failed to generate quiz: {str(e)}")

# --- Performance Summary ---
st.header("ðŸ“Š Performance Summary")

try:
    df = pd.read_csv(log_path)
    correct_total = df["correct"].sum()
    incorrect_total = len(df) - correct_total

    st.write(f"Total Questions Answered: {len(df)}")
    st.write(f"âœ… Correct: {correct_total}")
    st.write(f"âŒ Incorrect: {incorrect_total}")

    fig, ax = plt.subplots()
    ax.bar(["Correct", "Incorrect"], [correct_total, incorrect_total])
    ax.set_ylabel("Number of Responses")
    ax.set_title("Student Performance")
    st.pyplot(fig)

except Exception as e:
    st.warning("âš ï¸ No grading data available or error reading log.")
    st.text(str(e))
